{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e4d1bb",
   "metadata": {},
   "source": [
    "# ML Model Selection for the Titanic Survivor Problem\n",
    "## Creating a model to predict the survivors of the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716645e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a8f230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "test_data['Survived'] = np.nan\n",
    "\n",
    "data = pd.concat([train_data,test_data])\n",
    "\n",
    "# Encode the Sex category\n",
    "data['Male'] = data.Sex.apply(lambda x: 1 if x == 'male' else 0)\n",
    "data['Female'] = data.Sex.apply(lambda x: 1 if x == 'female' else 0)\n",
    "data.drop('Sex', axis=1, inplace=True)\n",
    "\n",
    "# Extract Title from name - could be useful\n",
    "data['Title'] = data.Name.apply(lambda x: x.split('.')[0].split(' ')[-1])\n",
    "\n",
    "# I am going to fill in the people with NaN for age, using their title as an indication of age - i.e. NaN will be\n",
    "## replaced with average age of people with the same title (e.g. Master and Miss usually refer to younger people)\n",
    "\n",
    "title_vs_age = data.groupby('Title').Age.mean()\n",
    "\n",
    "data.Age = data.apply(lambda row: title_vs_age[row.Title] if math.isnan(row.Age) else row.Age, axis=1)\n",
    "\n",
    "# Remove 'Title' column now used\n",
    "data.drop('Title',axis=1, inplace=True)\n",
    "\n",
    "# Tidy ticket number and convert an integer - LINE values will be given the max ticket number +1 as these would have\n",
    "## the final assigned tickets if they weren't pre-booked (from inspection this is 3,101,317)\n",
    "\n",
    "data.Ticket = data.Ticket.apply(lambda x: 3101318 if x == 'LINE' else int(x.split(' ')[-1]))\n",
    "\n",
    "# Remove the Cabin data as 687 out of 891 entries are nan - this will not be useful for analysis\n",
    "data.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# I can't see any clues for the Embarked location of the passengers with NaN, so I will assign these to the largest\n",
    "## group and then encode these\n",
    "# print(data.Embarked.value_counts())\n",
    "data.Embarked = data.Embarked.apply(lambda x: 'S' if type(x) == float else x)\n",
    "\n",
    "encoded_E = pd.get_dummies(data.Embarked)\n",
    "\n",
    "data.join(encoded_E)\n",
    "\n",
    "data.drop('Embarked',axis=1, inplace=True)\n",
    "\n",
    "# 1 person has a Fare of NAN - replace with the mean Fare\n",
    "\n",
    "data.Fare = data.Fare.apply(lambda x: data.Fare.mean() if pd.isna(x) == True else x)\n",
    "\n",
    "data.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# print(data.head())\n",
    "train_data = data.iloc[:891]\n",
    "test_data = data.iloc[891:].drop(['Survived'], axis=1)\n",
    "\n",
    "y = train_data['Survived']\n",
    "X = train_data.drop(['Survived'], axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 10, train_size = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33b144f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=2, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=2, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=3, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=3, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=LinearDiscriminantAnalysis();, score=0.647 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=4, clf__kernel=poly, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=LinearDiscriminantAnalysis();, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=None;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=SVC(), clf__degree=4, clf__kernel=rbf, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=LinearDiscriminantAnalysis();, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=LinearDiscriminantAnalysis();, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=None;, score=0.649 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=None;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=None;, score=0.579 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=4, lda=None;, score=0.609 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=LinearDiscriminantAnalysis();, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=LinearDiscriminantAnalysis();, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=LinearDiscriminantAnalysis();, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=None;, score=0.649 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=None;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=None;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=None;, score=0.594 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=5, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=LinearDiscriminantAnalysis();, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=LinearDiscriminantAnalysis();, score=0.827 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=None;, score=0.642 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=None;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=None;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=None;, score=0.586 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=6, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=LinearDiscriminantAnalysis();, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=LinearDiscriminantAnalysis();, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=LinearDiscriminantAnalysis();, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=None;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=None;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=None;, score=0.612 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=None;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=7, lda=None;, score=0.586 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=LinearDiscriminantAnalysis();, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=LinearDiscriminantAnalysis();, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=LinearDiscriminantAnalysis();, score=0.827 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=None;, score=0.649 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=None;, score=0.642 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=None;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=None;, score=0.579 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=8, lda=None;, score=0.624 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=LinearDiscriminantAnalysis();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=LinearDiscriminantAnalysis();, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=None;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=None;, score=0.642 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=None;, score=0.590 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=None;, score=0.586 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=9, lda=None;, score=0.594 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=LinearDiscriminantAnalysis();, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=LinearDiscriminantAnalysis();, score=0.746 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=LinearDiscriminantAnalysis();, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=None;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=None;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=None;, score=0.612 total time=   0.0s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=None;, score=0.579 total time=   0.0s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(), clf__n_neighbors=10, lda=None;, score=0.586 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BenPollins/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=LinearDiscriminantAnalysis();, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=LinearDiscriminantAnalysis();, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=LinearDiscriminantAnalysis();, score=0.716 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=LinearDiscriminantAnalysis();, score=0.820 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=None;, score=0.754 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=None;, score=0.881 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=None;, score=0.754 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=None;, score=0.812 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=5, lda=None;, score=0.835 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=LinearDiscriminantAnalysis();, score=0.746 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=LinearDiscriminantAnalysis();, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=LinearDiscriminantAnalysis();, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=None;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=None;, score=0.881 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=None;, score=0.761 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=6, lda=None;, score=0.835 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=LinearDiscriminantAnalysis();, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=LinearDiscriminantAnalysis();, score=0.806 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=LinearDiscriminantAnalysis();, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=None;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=None;, score=0.866 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=None;, score=0.761 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=None;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=7, lda=None;, score=0.827 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=LinearDiscriminantAnalysis();, score=0.813 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=LinearDiscriminantAnalysis();, score=0.709 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=None;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=None;, score=0.873 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=None;, score=0.769 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=8, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=LinearDiscriminantAnalysis();, score=0.746 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=LinearDiscriminantAnalysis();, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=LinearDiscriminantAnalysis();, score=0.701 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=LinearDiscriminantAnalysis();, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=LinearDiscriminantAnalysis();, score=0.767 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=None;, score=0.806 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=None;, score=0.858 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=None;, score=0.754 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=None;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=9, lda=None;, score=0.827 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=LinearDiscriminantAnalysis();, score=0.746 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=LinearDiscriminantAnalysis();, score=0.799 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=LinearDiscriminantAnalysis();, score=0.694 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=LinearDiscriminantAnalysis();, score=0.752 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=LinearDiscriminantAnalysis();, score=0.752 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=None;, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=None;, score=0.851 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=None;, score=0.806 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=None;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=10, lda=None;, score=0.842 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=LinearDiscriminantAnalysis();, score=0.731 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=LinearDiscriminantAnalysis();, score=0.791 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=LinearDiscriminantAnalysis();, score=0.687 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=LinearDiscriminantAnalysis();, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=LinearDiscriminantAnalysis();, score=0.737 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=None;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=None;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=None;, score=0.769 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=11, lda=None;, score=0.812 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=LinearDiscriminantAnalysis();, score=0.709 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=LinearDiscriminantAnalysis();, score=0.799 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=LinearDiscriminantAnalysis();, score=0.694 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=LinearDiscriminantAnalysis();, score=0.767 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=LinearDiscriminantAnalysis();, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=None;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=None;, score=0.851 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=None;, score=0.776 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=None;, score=0.797 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=12, lda=None;, score=0.827 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=LinearDiscriminantAnalysis();, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=LinearDiscriminantAnalysis();, score=0.791 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=LinearDiscriminantAnalysis();, score=0.687 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=LinearDiscriminantAnalysis();, score=0.737 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=LinearDiscriminantAnalysis();, score=0.684 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=None;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=None;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=None;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=13, lda=None;, score=0.827 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=LinearDiscriminantAnalysis();, score=0.701 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=LinearDiscriminantAnalysis();, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=LinearDiscriminantAnalysis();, score=0.672 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=LinearDiscriminantAnalysis();, score=0.752 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=LinearDiscriminantAnalysis();, score=0.684 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=None;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=None;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=None;, score=0.791 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=None;, score=0.827 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=14, lda=None;, score=0.805 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=LinearDiscriminantAnalysis();, score=0.701 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=LinearDiscriminantAnalysis();, score=0.754 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=LinearDiscriminantAnalysis();, score=0.657 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=LinearDiscriminantAnalysis();, score=0.752 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=LinearDiscriminantAnalysis();, score=0.684 total time=   0.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=None;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=None;, score=0.851 total time=   0.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=None;, score=0.791 total time=   0.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=None;, score=0.812 total time=   0.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(), clf__max_depth=15, lda=None;, score=0.835 total time=   0.1s\n",
      "Pipeline(steps=[('lda', None), ('clf', RandomForestClassifier(max_depth=10))])\n",
      "0.8654708520179372\n"
     ]
    }
   ],
   "source": [
    "# Coarse Model Selection\n",
    "\n",
    "model_pipeline = Pipeline([('lda', LinearDiscriminantAnalysis()), ('clf', SVC())])\n",
    "\n",
    "model_param_1 = {'lda': [LinearDiscriminantAnalysis(), None], 'clf': [SVC()], \n",
    "                 'clf__kernel': ['poly', 'rbf'], 'clf__degree': [2, 3, 4]}\n",
    "\n",
    "model_param_2 = {'lda': [LinearDiscriminantAnalysis(), None], 'clf': [KNeighborsClassifier()], \n",
    "                 'clf__n_neighbors': list(range(4, 11))}\n",
    "\n",
    "model_param_3 = {'lda': [LinearDiscriminantAnalysis(), None], 'clf': [RandomForestClassifier()], \n",
    "                 'clf__max_depth': list(range(5, 16))}\n",
    "\n",
    "model_param_grid = [model_param_1, model_param_2, model_param_3]\n",
    "\n",
    "model_grid = GridSearchCV(model_pipeline, model_param_grid, cv=5, verbose=3, error_score='raise')\n",
    "\n",
    "model_grid.fit(X_train, y_train)\n",
    "\n",
    "print(model_grid.best_estimator_)\n",
    "\n",
    "print(model_grid.best_estimator_.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1bd5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Features:\n",
      "0.8878923766816144\n",
      "7 Features:\n",
      "0.8609865470852018\n",
      "8 Features:\n",
      "0.874439461883408\n",
      "9 Features:\n",
      "0.8609865470852018\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "\n",
    "base_pipeline = model_grid.best_estimator_\n",
    "scores = []\n",
    "features = []\n",
    "\n",
    "# print(base_pipeline)\n",
    "\n",
    "for x in range(6,9):\n",
    "    sbs = SFS(base_pipeline, n_features_to_select=x, direction='backward', scoring='accuracy', cv=10)\n",
    "\n",
    "    sbs.fit(X_train, y_train)\n",
    "\n",
    "    selected_features = [X_train.columns[i] for i in sbs.get_support(indices=True)]\n",
    "\n",
    "    X_train_reduced = X_train[selected_features]\n",
    "\n",
    "    X_val_reduced = X_val[selected_features]\n",
    "\n",
    "    base_pipeline.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    print(f'{x} Features:')\n",
    "    print(base_pipeline.score(X_val_reduced, y_val))\n",
    "    \n",
    "    scores.append(base_pipeline.score(X_val_reduced, y_val))\n",
    "    features.append(selected_features)\n",
    "\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('9 Features:')\n",
    "print(base_pipeline.score(X_val, y_val))\n",
    "\n",
    "if max(scores) >= base_pipeline.score(X_val, y_val):\n",
    "    selected_features = features[scores.index(max(scores))]\n",
    "\n",
    "else:\n",
    "    selected_features = X_train.columns\n",
    "\n",
    "X_train_reduced = X_train[selected_features]\n",
    "X_val_reduced = X_val[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2db8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Pipeline(steps=[('lda', None),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=12))])\n",
      "0.8654708520179372\n"
     ]
    }
   ],
   "source": [
    "# Model Fine-Tuning\n",
    "\n",
    "fine_tune_params = {'clf__max_depth': list(range(best_pipeline['clf'].max_depth-2, best_pipeline['clf'].max_depth+3)),\n",
    "                   'clf__criterion': ['gini', 'entropy'], 'clf__n_estimators': [100, 150, 200, 250]}\n",
    "\n",
    "fine_tune_grid = GridSearchCV(best_pipeline, fine_tune_params, cv=10, verbose=1)\n",
    "\n",
    "\n",
    "fine_tune_grid.fit(X_train_reduced, y_train)\n",
    "\n",
    "\n",
    "tuned_model = fine_tune_grid.best_estimator_\n",
    "\n",
    "print(tuned_model)\n",
    "\n",
    "print(tuned_model.score(X_val_reduced, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f59c05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict outcomes\n",
    "total_train_data = pd.concat([X_train_reduced, X_val_reduced])\n",
    "total_train_results = pd.concat([y_train,y_val])\n",
    "\n",
    "tuned_model.fit(total_train_data, total_train_results)\n",
    "\n",
    "test_data_reduced = test_data[selected_features]\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "predictions['PassengerId'] = test_data.PassengerId\n",
    "predictions['Survived'] = tuned_model.predict(test_data_reduced).astype('int')\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "predictions.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
